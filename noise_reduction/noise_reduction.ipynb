{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f936e1-d2c1-4486-8ca1-a53eb046f990",
   "metadata": {},
   "source": [
    "# Removing Noise in Images using Median and Bilateral Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941a7696-e902-44f0-a40a-c87bcd1ec14c",
   "metadata": {},
   "source": [
    "We have seen linear filters such as the box filter and Gaussian Filter in image smoothing. We will now see how we can use filters to remove noise from an image. First, let us start by creating some noise in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd413d05-ee17-426b-8e33-80c95e9c63f9",
   "metadata": {},
   "source": [
    "We will create Gaussian, Uniform and Impulse ('salt and pepper') noise. We will then apply the various filters to see their effects on images. Some of the material in this section is sourced from [Kaggle](https://www.kaggle.com/code/chanduanilkumar/adding-and-removing-image-noise-in-python/notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c14bb1-a824-4f7a-99ff-d5dcaaf7197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa03825-fbe2-414c-aaa9-713331ef284f",
   "metadata": {},
   "source": [
    "### Gaussian Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaffe55-cbcf-4362-ba29-f970acbb8e0b",
   "metadata": {},
   "source": [
    "Also known as electronic noise. It is caused by the discrete nature of radiation of warm objects. To create this noise we use a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4c429-97b7-491d-a5b4-13fe2b53681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(img, mean, stddev, gamma = 1):\n",
    "    #Create Gaussian Noise\n",
    "    gauss_noise = np.zeros(img.shape[:2])\n",
    "    cv2.randn(gauss_noise, mean, stddev)\n",
    "    gauss_noise = (gauss_noise*gamma).astype(np.uint8)\n",
    "    \n",
    "    if len(img.shape) == 2:\n",
    "        output = cv2.add(img, gauss_noise)\n",
    "    elif len(img.shape) == 3:\n",
    "        merged = cv2.merge([gauss_noise, gauss_noise, gauss_noise])\n",
    "        output = cv2.add(img, merged)\n",
    "    return gauss_noise, output\n",
    "        \n",
    "\n",
    "def gaussian_noise_b(img, mean, stddev, gamma = 1):\n",
    "    gauss_noise = np.random.normal(mean/255, stddev/255, img.shape[:2]) * 255\n",
    "    gauss_noise = gauss_noise + np.abs(gauss_noise.min())\n",
    "    gauss_noise = (gauss_noise*gamma).astype(np.uint8)\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        final = np.clip((gauss_noise + img), 0, 255).astype(np.uint8)\n",
    "        return final\n",
    "    elif len(img.shape) == 3:\n",
    "        final = img.copy()\n",
    "        for channel in range(img.shape[2]):\n",
    "            final[:, :, channel] = np.clip((gauss_noise + img[:, :, channel]), 0, 255).astype(np.uint8)\n",
    "            \n",
    "        return gauss_noise, final\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e143d56-8c62-4d85-9cde-759723c46454",
   "metadata": {},
   "source": [
    "### Uniform Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d3c25a-a21f-44db-b87e-e632092ba6aa",
   "metadata": {},
   "source": [
    "As the name suggests, this type of noise follows a uniform distribution. It is caused by the quantization of image pixels to a number of discrete levels. To create a Uniform noise, we create a uniform distribution whose lower and upper bounds are the minimum and maximum pixel values (0 and 255 respectively) along the dimensions of the image. In this type of noise, the measured pixel image values are equally likely to be spread across a range of possible values either side of the true value. Hence, the PDF of the recorded value of each pixel value takes the form of a rectangle either side of the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27932f-ef6e-45b8-8383-3206901beccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_noise(img, gamma=1):\n",
    "    uni_noise = np.zeros(img.shape[:2])\n",
    "    cv2.randu(uni_noise, 0, 256)\n",
    "    uni_noise = (uni_noise * gamma).astype(np.uint8)\n",
    "    \n",
    "    if len(img.shape) == 2:\n",
    "        output = cv2.add(img, uni_noise)\n",
    "    elif len(img.shape) == 3:\n",
    "        merged = cv2.merge([uni_noise, uni_noise, uni_noise])\n",
    "        output = cv2.add(img, merged)\n",
    "    return uni_noise, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df58b7d-7fd0-4c3c-a0fe-f01580313d10",
   "metadata": {},
   "source": [
    "### Impulse / 'Salt and Pepper' Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71466a90-6343-48c1-ac68-40b8741c2d59",
   "metadata": {},
   "source": [
    "Impulse or \"Salt and Pepper\" noise is the sparse occurance of maximum (255) and minimum (0) pixel values in an image. This can be noticed as the presence of black pixels in bright regions and white pixels in dark regions. This type of noise is caused due to sharp and sudden disturbances in the image signal, and is mainly generated by errors in analog to digital conversion or bit transmission.\n",
    "\n",
    "To create a Salt and Pepper noise, we first create a distribution similar to that used in Uniform noise and apply binary thresholding to create a grid of black and white pixels. The intensity of the noise can be easily altered by changing the threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59beef9-f074-4035-8694-0f42b3273dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salt_pepper_noise(img, prob = 0.5):\n",
    "    '''\n",
    "    Add salt and pepper noise to image\n",
    "    prob: Probability of the noise\n",
    "    '''\n",
    "    output = img.copy()\n",
    "    sp_noise = np.zeros_like(img)\n",
    "    if len(img.shape) == 2:\n",
    "        black = 0\n",
    "        white = 255            \n",
    "    else:\n",
    "        colorspace = img.shape[2]\n",
    "        if colorspace == 3:  # RGB\n",
    "            black = np.array([0, 0, 0], dtype='uint8')\n",
    "            white = np.array([255, 255, 255], dtype='uint8')\n",
    "        else:  # RGBA\n",
    "            black = np.array([0, 0, 0, 255], dtype='uint8')\n",
    "            white = np.array([255, 255, 255, 255], dtype='uint8')\n",
    "    probs = np.random.random(output.shape[:2])\n",
    "    output[probs < (prob / 2)] = black\n",
    "    output[probs > 1 - (prob / 2)] = white\n",
    "    sp_noise[probs < (prob / 2)] = black\n",
    "    sp_noise[probs > 1 - (prob / 2)] = white\n",
    "    return sp_noise, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18f177-6882-486a-bd16-b20567433561",
   "metadata": {},
   "source": [
    "The [link](https://gist.github.com/gutierrezps/f4ddad3bbd2ad5a9b96e3c06378e28b4) for the above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5b0f7c-6712-4b73-b276-e0b317ca7f38",
   "metadata": {},
   "source": [
    "### Noise in images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6664539-5dcc-4004-8438-348c76813a73",
   "metadata": {},
   "source": [
    "Let us now look at how these types of noise can be recognized in images. Let us load the images we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b62370-bffc-4ec0-a191-72d9d223ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images\n",
    "lena = cv2.imread(\"images/lena.jpg\")\n",
    "flower = cv2.imread(\"images/flower.jpg\")\n",
    "\n",
    "plt.figure(figsize=[15, 5])\n",
    "plt.subplot(121); plt.imshow(lena[:, :, ::-1])\n",
    "_ = plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(122); plt.imshow(flower[:, :, ::-1])\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df25424-d139-4ca0-a714-ee8af1ebad15",
   "metadata": {},
   "source": [
    "We will now create the utility function to plot the image, the noise and the resultant image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a19512e-f6ba-41b0-a977-a3306572f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noise_image(img, noise, noisy_img, noise_type=''):\n",
    "    plt.figure(figsize=[15, 5])\n",
    "    plt.subplot(131); plt.imshow(img[:, :, ::-1]); plt.title('Original Image'); plt.axis(\"off\")\n",
    "    plt.subplot(132); plt.imshow(noise); plt.title(noise_type + ' Noise'); plt.axis(\"off\")\n",
    "    plt.subplot(133); plt.imshow(noisy_img[:, :, ::-1]); plt.title('Image with ' + noise_type + ' Noise'); plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f344bbb-a38f-4a62-9976-1de48d508987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian noise\n",
    "gauss_noise_lena, gauss_img_lena = gaussian_noise(lena, 128, 127, .3)\n",
    "plot_noise_image(lena, gauss_noise_lena, gauss_img_lena, 'Gaussian')\n",
    "\n",
    "# uniform noise\n",
    "uni_noise_lena, uni_img_lena = uniform_noise(lena, .5)\n",
    "plot_noise_image(lena, uni_noise_lena, uni_img_lena, 'Uniform')\n",
    "\n",
    "imp_noise_lena, imp_img_lena = salt_pepper_noise(lena, .05)\n",
    "plot_noise_image(lena, imp_noise_lena, imp_img_lena, 'Salt and Pepper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fab56e-5f28-44ab-a77c-a8b5c751a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian noise\n",
    "gauss_noise_flower, gauss_img_flower = gaussian_noise(flower, 128, 127, .3)\n",
    "plot_noise_image(flower, gauss_noise_flower, gauss_img_flower, 'Gaussian')\n",
    "\n",
    "# uniform noise\n",
    "uni_noise_flower, uni_img_flower = uniform_noise(flower, .6)\n",
    "plot_noise_image(flower, uni_noise_flower, uni_img_flower, 'Uniform')\n",
    "\n",
    "# Salt & pepper noise\n",
    "imp_noise_flower, imp_img_flower = salt_pepper_noise(flower, .2)\n",
    "plot_noise_image(flower, imp_noise_flower, imp_img_flower, 'Salt and Pepper')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c9b307-e8c3-4b74-b916-b162bebc7b95",
   "metadata": {},
   "source": [
    "### Filtering for Noise Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020e0080-e8d6-4c47-885e-eaf482bbabe2",
   "metadata": {},
   "source": [
    "### Median Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b392c4d-464e-4eb0-9df9-c7832585c590",
   "metadata": {},
   "source": [
    "Median blur filtering is a nonlinear filtering technique that is most commonly used to remove **salt-and-pepper noise** from images. As the name suggests, salt-and-pepper noise shows up as randomly occurring white and black pixels that are sharply different from the surrounding. In color images, salt-and-pepper noise may appear as small random color spots.\n",
    "\n",
    "The median filter sets the central pixel in a neighborhood as the median value of the pixels in the neighborhood. We can use OpenCV's `medianBlur()` for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8784ce7-2a43-4747-8690-d143d71a79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_flower_median_imp = cv2.medianBlur(imp_img_flower, 5)\n",
    "smooth_lena_median_imp = cv2.medianBlur(imp_img_lena, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf351cf-f18c-4b4d-83f5-bbbfc5de85c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=[15, 9], layout='tight')\n",
    "\n",
    "labels = ['Original', 'Image with Impulse Noise', 'Median Smoothed Image']\n",
    "images = [lena, imp_img_lena, smooth_lena_median_imp, flower, imp_img_flower, smooth_flower_median_imp]\n",
    "\n",
    "for pos, ax in enumerate(axs.flat):\n",
    "    ax.imshow(images[pos][:, :, ::-1]); ax.set_title(labels[pos%3]); ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e4e3af-b22e-4130-bd4b-b47d51d90acf",
   "metadata": {},
   "source": [
    "We can see that the median filter works very well with salt-and-pepper noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7052d-21c1-46be-a741-288e91d608a2",
   "metadata": {},
   "source": [
    "### Gaussian Blur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55850b-6a78-4fec-abeb-b92093fc7736",
   "metadata": {},
   "source": [
    "Gaussian blur can also be used to remove noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea355b-9835-46a1-bf7b-06fa7807d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_flower_gauss_gauss = cv2.GaussianBlur(gauss_img_flower, (11, 11), 20)\n",
    "smooth_lena_gauss_gauss = cv2.GaussianBlur(gauss_img_lena, (5, 5), 11)\n",
    "\n",
    "fig_2, axs_2 = plt.subplots(2, 3, figsize=[15, 9], layout='tight')\n",
    "\n",
    "labels_gauss = ['Original', 'Image with Gaussian Noise', 'Gaussian Smoothed Image']\n",
    "images_gauss = [lena, gauss_img_lena, smooth_lena_gauss_gauss, flower, gauss_img_flower, smooth_flower_gauss_gauss]\n",
    "\n",
    "for pos, ax in enumerate(axs_2.flat):\n",
    "    ax.imshow(images_gauss[pos][:, :, ::-1]); ax.set_title(labels_gauss[pos%3]); ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6befac8-33cc-4ba6-8f68-5a0f6486b196",
   "metadata": {},
   "source": [
    "Although we managed to remove some bit of noise from the images above, we can see that we have lost a considerable bit of detail in the process. We can better deal with this problem by using a blurring filter that smooths while preserving the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba042091-b369-44b3-b2ca-3844bf777032",
   "metadata": {},
   "source": [
    "### Bilateral Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7c69b-7c50-4c90-99f6-b64564efffb6",
   "metadata": {},
   "source": [
    "We are going to apply this bilateral edge-preserving filter to the images with gaussian noise above and see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b5e00-cc23-4c2b-bfd7-c8f45b05752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_lena_gauss_bil = cv2.bilateralFilter(gauss_img_lena, 20, 120, 300)\n",
    "smooth_flower_gauss_bil = cv2.bilateralFilter(gauss_img_flower, 20, 120, 300)\n",
    "\n",
    "fig_3, axs_3 = plt.subplots(2, 3, figsize=[15, 9], layout='tight')\n",
    "\n",
    "labels_bil = ['Image with Gaussian Noise', 'Filtered using Gaussian Filter', 'Filtered using Bilateral Filter']\n",
    "images_bil = [gauss_img_lena, smooth_lena_gauss_gauss, smooth_lena_gauss_bil,\\\n",
    "                gauss_img_flower, smooth_flower_gauss_gauss, smooth_flower_gauss_bil]\n",
    "\n",
    "for pos, ax in enumerate(axs_3.flat):\n",
    "    ax.imshow(images_bil[pos][:, :, ::-1]); ax.set_title(labels_bil[pos%3]); ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ed37e-9d34-479f-a813-bf2c3de098eb",
   "metadata": {},
   "source": [
    "We can see the difference that the bilateral filter brings to the table. It smooths the image while still retaining the edges. If the values of Sigma are enlarged further, the resultant image could have a comical effect to it. This is what is used in other camera image filters to smooth skin. However, it should be noted that the Bilateral filter can be quite slow compared to other smoothing filters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1281b-3054-4112-be6e-5dfbd08ac804",
   "metadata": {},
   "source": [
    "### Using `fastNlMeansDenoising`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2339fd-aab7-4929-b4ce-3f2cd2b42b9c",
   "metadata": {},
   "source": [
    "We are going to use the OpenCV method, `fastNlMeansDenoising` to denoise the image. It expects an image with Gaussian white noise. Since our images are colored, we will use `fastNlMeansDenoisingColored`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4852bcc7-8a6e-4329-90f7-ae29d1abc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_lena_gauss_nl = cv2.fastNlMeansDenoisingColored(gauss_img_lena, None, 10, 10, 5, 19)\n",
    "\n",
    "plt.figure(figsize=[15, 5])\n",
    "plt.subplot(121); plt.imshow(gauss_img_lena[:, :, ::-1]); plt.title('Image with Gaussian Noise'); plt.axis(\"off\")\n",
    "plt.subplot(122); plt.imshow(smooth_lena_gauss_nl[:, :, ::-1]); plt.title('Denoised with non-local Denoising'); plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ae164-5e1a-4fd0-ab35-f3c5ca58db4e",
   "metadata": {},
   "source": [
    "The results of the non-local denoiser are comparable to the bilateral filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0452a1de-e377-40ab-89b8-e1e646e63d3b",
   "metadata": {},
   "source": [
    "### Filtering an image with Uniform Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c2e12-ca59-47a2-869a-6320516cc736",
   "metadata": {},
   "source": [
    "Since uniform noise basically means that a pixel is equally-likely to have as its value a range of values, we can use a mean filter to smooth out an image and reduce the noise. We set the central pixel as the mean of values in a neighborhood. This method, however, suffers from the same effect as the median filter, in that, edges are blurred too. We will also compare its result against the Bilateral filter over the same image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b705b-cc0c-40d6-b473-374c9c7baef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st image smoothed with box filter and bilateral filter\n",
    "smooth_lena_uni_mean = cv2.blur(uni_img_lena, (5, 5))\n",
    "smooth_lena_uni_bil = cv2.bilateralFilter(uni_img_lena, 20, 130, 50)\n",
    "\n",
    "# 2nd image smoothed with box filter and bilateral filter\n",
    "smooth_flower_uni_mean = cv2.blur(uni_img_flower, (7, 7))\n",
    "smooth_flower_uni_bil = cv2.bilateralFilter(uni_img_flower, 20, 130, 50)\n",
    "\n",
    "\n",
    "fig_4, axs_4 = plt.subplots(2, 3, figsize=[15, 9], layout='tight')\n",
    "\n",
    "labels_uni_bil = ['Image with Uniform Noise', 'Filtered using Mean Filter', 'Filtered using Bilateral Filter']\n",
    "images_uni_bil = [uni_img_lena, smooth_lena_uni_mean, smooth_lena_uni_bil,\\\n",
    "                uni_img_flower, smooth_flower_uni_mean, smooth_flower_uni_bil]\n",
    "\n",
    "for pos, ax in enumerate(axs_4.flat):\n",
    "    ax.imshow(images_uni_bil[pos][:, :, ::-1]); ax.set_title(labels_uni_bil[pos%3]); ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6861e4-141d-4c96-97bb-5abc67ac998c",
   "metadata": {},
   "source": [
    "We see that there is a considerable difference in image quality and noise reduction between the mean filter and bilateral filters. However, we could say that what the mean filter lacks in detail, it makes up for in speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7add2-1b42-47c8-8102-e6f936641a8a",
   "metadata": {},
   "source": [
    "### The Spectral differences between original and noisy images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270dc320-a15e-43fb-8d72-70c9937aca1d",
   "metadata": {},
   "source": [
    "We will now look at the Fourier transforms of the original and noisy images to see if there are any discernable differences in the Fourier space. We will have to work with our images in grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e72b20d-2078-431b-b39b-3f6890b2c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_fft(img):\n",
    "    '''Utility function that returns the fft of an img.\n",
    "    Also, in this case, since the images are 3-channel, it\n",
    "    will return a 1-channel image.'''\n",
    "\n",
    "    if len(img.shape) > 2:\n",
    "        # assume RGB\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img_gray = img.copy()\n",
    "\n",
    "    gray_fft = np.fft.fft2(img_gray)\n",
    "    gray_fft_shift = np.fft.fftshift(gray_fft)\n",
    "\n",
    "    #make suitable for plotting\n",
    "    gray_fft_suit = np.abs(np.log(gray_fft_shift + 10**-35))\n",
    "\n",
    "    return img_gray, gray_fft_suit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708e60f-1cb8-4041-bc38-c7727f766d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_lena = [lena, gauss_img_lena, uni_img_lena, imp_img_lena]\n",
    "titles_lena = ['Original', 'With Gaussian Noise', 'With Uniform Noise', 'With Impulse Noise']\n",
    "\n",
    "images_plot_gray = []\n",
    "images_plot_fft = []\n",
    "\n",
    "for image in images_lena:\n",
    "    gray, fft = return_fft(image)\n",
    "    images_plot_gray.append(gray)\n",
    "    images_plot_fft.append(fft)\n",
    "\n",
    "\n",
    "fig_5, axs_5 = plt.subplots(2, 4, figsize=[22, 12], layout='tight')\n",
    "\n",
    "for pos, ax in enumerate(axs_5[0]):\n",
    "    ax.imshow(images_plot_gray[pos]); ax.set_title(titles_lena[pos]); ax.axis('off')\n",
    "\n",
    "for pos, ax in enumerate(axs_5[1]):\n",
    "    ax.imshow(images_plot_fft[pos], cmap='viridis'); ax.set_title(titles_lena[pos] + ' FFT'); ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c5549-9f8c-44c4-9b75-6105809e9e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_flower = [flower, gauss_img_flower, uni_img_flower, imp_img_flower]\n",
    "titles_flower = ['Original', 'With Gaussian Noise', 'With Uniform Noise', 'With Impulse Noise']\n",
    "\n",
    "images_plot_gray_f = []\n",
    "images_plot_fft_f = []\n",
    "\n",
    "for image in images_flower:\n",
    "    gray, fft = return_fft(image)\n",
    "    images_plot_gray_f.append(gray)\n",
    "    images_plot_fft_f.append(fft)\n",
    "\n",
    "\n",
    "fig_6, axs_6 = plt.subplots(2, 4, figsize=[22, 12], layout='tight')\n",
    "\n",
    "for pos, ax in enumerate(axs_6[0]):\n",
    "    ax.imshow(images_plot_gray_f[pos]); ax.set_title(titles_flower[pos]); ax.axis('off')\n",
    "\n",
    "for pos, ax in enumerate(axs_6[1]):\n",
    "    ax.imshow(images_plot_fft_f[pos], cmap='viridis'); ax.set_title(titles_flower[pos] + ' FFT'); ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957a195-0b13-4d86-a225-c2674d4c8335",
   "metadata": {},
   "source": [
    "We see that the high-frequency components of the original image are removed in the noisy images. Let us now look at how the frequency spectrum chnages as we increase the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23efbafb-0a5f-4ed4-b605-8a0d283d7310",
   "metadata": {},
   "source": [
    "### Change in Frequency as Noise is Increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de993d-5adf-4575-81cf-13169a930b7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lena_5 = gaussian_noise(lena, 128, 127, .005)[1]\n",
    "lena_25 = gaussian_noise(lena, 128, 127, .01)[1]\n",
    "lena_60 = gaussian_noise(lena, 128, 127, .05)[1]\n",
    "lena_100 = gaussian_noise(lena, 128, 127, .15)[1]\n",
    "\n",
    "images_lena_gauss = [lena, lena_5, lena_25, lena_60, lena_100]\n",
    "titles_lena_gauss = ['Original', '0.5% Gaussian Noise', '1% Gaussian Noise', '5% Gaussian Noise', '15% Gaussian Noise']\n",
    "\n",
    "images_plot_gray_cf = []\n",
    "images_plot_fft_cf = []\n",
    "\n",
    "for image in images_lena_gauss:\n",
    "    gray, fft = return_fft(image)\n",
    "    images_plot_gray_cf.append(gray)\n",
    "    images_plot_fft_cf.append(fft)\n",
    "\n",
    "\n",
    "fig_7, axs_7 = plt.subplots(5, 2, figsize=[12, 25], layout='tight')\n",
    "\n",
    "for pos, row in enumerate(axs_7):\n",
    "    row[0].imshow(images_plot_gray_cf[pos]); row[0].set_title(titles_lena_gauss[pos]); row[0].axis('off')\n",
    "    row[1].imshow(images_plot_fft_cf[pos], cmap='viridis'); row[1].set_title(titles_lena_gauss[pos] + ' FFT'); row[1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25403c7-3736-4a8e-b18c-ce5f3ace7fc5",
   "metadata": {},
   "source": [
    "In the above plot, we have created some Gaussian noise in the test image ranging from 0.5 - 15%. We quickly see from the frequency plot, that as the noise level increases, the high-frequency image components of the image are removed leaving us with only the low-freq. components. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf180dc6-6321-4e0f-a723-f0703ebc82e2",
   "metadata": {},
   "source": [
    "### Magnitude and Phase shift from Original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29631ab7-fc1d-4f92-a703-1982e0e58d8b",
   "metadata": {},
   "source": [
    "We will now plot the magnitude and phase angle of the original image and compare it with the same plot of an image with 15% noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e82b8-92f2-4740-9e90-c33fb36b21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot an image and its magnitude\n",
    "def plot_polar_image(img, title=''):\n",
    "    \"\"\"\n",
    "    Given any image, we will produce the Argand diagram\n",
    "    of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(img.shape) > 2:\n",
    "        # assume RGB\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img_gray = img.copy()\n",
    "\n",
    "    gray_fft = np.fft.fft2(img_gray)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(6 * 2, 4)\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    ax1.imshow(img_gray), ax1.axis(\"off\")\n",
    "\n",
    "    # Plot each complex number as an arrow\n",
    "    for num in gray_fft.flat:\n",
    "        #plot as a ~1/10 of the original\n",
    "        ax2.arrow(0, 0, num.real/3, num.imag/3, head_width=0.1,\n",
    "                  head_length=0.2, fc='blue', ec='blue')\n",
    "\n",
    "    \n",
    "    # Set the limits of the plot\n",
    "    ax2.set_xlim(-15000, 15000);\n",
    "    ax2.set_ylim(-15000, 15000);\n",
    "    ax2.set_xlabel('Re');\n",
    "    ax2.set_ylabel('Im');\n",
    "    ax2.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de0f8e-cdd1-4409-8355-164828091c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100% gaussian noise\n",
    "lena_100_true = gaussian_noise(lena, 128, 127)[1]\n",
    "lena_100_small = cv2.resize(lena_100_true, None, fx=.25, fy=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad762424-d903-4bd2-9248-9b37e40fb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "lena_small = cv2.resize(lena, None, fx=.25, fy=.25)\n",
    "lena_15_small = cv2.resize(lena_100, None, fx=.25, fy=.25)\n",
    "plot_polar_image(lena_small, 'Original')\n",
    "plot_polar_image(lena_15_small, '15% Gaussian Noise')\n",
    "plot_polar_image(lena_100_small, '100% Gaussian Noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f0193d-9357-4df9-9819-880af5e49e0c",
   "metadata": {},
   "source": [
    "What we can see from the plot above is that there is a significant change in the image magnitude, while the phase angle remains relatively the same."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-env",
   "language": "python",
   "name": "opencv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
