{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c1a9c6-ebda-46d3-b1ac-d796080bfc76",
   "metadata": {},
   "source": [
    "# Understanding Aruco Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000cf38-4473-4885-ab31-6c9bc3d53ff3",
   "metadata": {},
   "source": [
    "ArUco markers are square black and white images with a unique id that are used to mark 3D planes coplanar points. Since they are unique, they can easily map 3D coplanar points into 2D images. They are used for Augmented Reality, Camera Calibration and pose estimation among others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425970fe-93ce-443c-b49d-fe7c58b8d6d3",
   "metadata": {},
   "source": [
    "OpenCV provides the ArUco module with which we can draw, detect and draw detected markers.\n",
    "\n",
    "As stated, each AruCo marker is unique as to the pattern. Markers with the same internal size are grouped into a dictionary. ArUco dictionaries contain a number of squares that have the same internal size.\n",
    "\n",
    "OpenCV provides predefined dictionaries such as DICT_6x6_250... where 6x6 is the marker size in bits and 250 is the number of markers in the dictionary. Each ArUco marker has a unique ID starting from 0 to N-1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b70db2c-419c-4bf1-93f1-9376a8e8a49b",
   "metadata": {},
   "source": [
    "### Loading and displaying ArUco Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad5d93b-664a-41ac-9634-c04f17390202",
   "metadata": {},
   "source": [
    "Let us load and display a few ArUco markers. We will use OpenCV's `getPredefinedDictionary` method to load a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64617ff-3dd0-4824-be05-172ce9b1d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f381f-12c7-406f-954b-56567870aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "[m for m in dir(cv2.aruco) if 'DICT' in m]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460361a-f82f-40b1-a42b-1e3f3f4df0f2",
   "metadata": {},
   "source": [
    "Some of the existing dictionaries. More information can be found [here](https://docs.opencv.org/4.x/de/d67/group__objdetect__aruco.html#gga4e13135a118f497c6172311d601ce00da6235dfb8007de53d3e8de11bee1e3854)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065c0f4-c0ef-4743-8460-12ef66951b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us load one dictionary\n",
    "dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_7X7_250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189959ef-705d-4535-a998-5a9a85cfb745",
   "metadata": {},
   "source": [
    "We can now generate a number of markers from these dictionaries and display them. We will use the `generateImageMarker` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad29c3-4a4b-4751-b0c6-9e599c8ac713",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = [10, 197, 60]\n",
    "aruco_markers = []\n",
    "for marker in markers:\n",
    "    aruco_markers.append(dictionary.generateImageMarker(marker, 200))\n",
    "\n",
    "print(aruco_markers[0].shape)\n",
    "len(aruco_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d3eca-965f-479b-8fae-b4f5d12535c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "plt.subplot(131); plt.imshow(aruco_markers[0]); plt.axis('off')\n",
    "plt.subplot(132); plt.imshow(aruco_markers[1]); plt.axis('off')\n",
    "plt.subplot(133); plt.imshow(aruco_markers[2]); plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd326b-2428-4e2e-ad26-4dc6835fc995",
   "metadata": {},
   "source": [
    "We have displayed 3 images taken from DICT_7X7_250 with a size of 7x7 boxes. We have scaled the output to 200x200 size.\n",
    "\n",
    "Normally, the images are then saved and printed to be placed in real-world objects. These markers can then be used to define the ROI of an image. This is done by detecting a corner of an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d573e72d-8569-4602-add3-3b6ea02a1a38",
   "metadata": {},
   "source": [
    "## AR using ArUco Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423e06e-72e5-4caa-85c7-ca78feefe509",
   "metadata": {},
   "source": [
    "We are going to use ArUco Markers to create an AR application.\n",
    "\n",
    "The steps are as follows:\n",
    "* Extract corner points of ArUco markers from image.\n",
    "* Determine ROI from corner points and scale ROI\n",
    "* Determine Source Image points\n",
    "* Warp Source into ROI shape\n",
    "* Create Source Mask\n",
    "* Add Source into initial image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298c62c-fe60-404f-bd71-e1ae47fe738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread('images/office_markers.jpg')\n",
    "\n",
    "plt.figure(figsize=[10, 10])\n",
    "plt.imshow(frame[:, :, ::-1]); plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b67a2b-302f-485b-ace0-9cf3028203fa",
   "metadata": {},
   "source": [
    "We are now going to detect the aruco markers. For that, we need to know the dictionary used. For this one, we know that the dictionary is 6x6_250, hence we start by loading it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23af433-43c0-4601-9053-925391a6569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict6 = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "corners, ids, rejects = cv2.aruco.detectMarkers(frame, dict6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524af76e-37a8-4989-83e3-f026a6332b24",
   "metadata": {},
   "source": [
    "The `detectMarkers` method returns the 4 corners of each ArUco object, the ids of each marker and any rejected would-be points. We can visualize this output by drawing using the method `drawDetectedMarkers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc6784-6fa1-4776-9a6f-14dd244f89a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the algorithm draws directly on the image\n",
    "frame_drawn = frame.copy()\n",
    "cv2.aruco.drawDetectedMarkers(frame_drawn, corners, ids)\n",
    "\n",
    "plt.figure(figsize=[20, 20])\n",
    "plt.imshow(frame_drawn[:, :, ::-1]); plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1dafb4-296d-4be8-805f-8f315eb4b0c5",
   "metadata": {},
   "source": [
    "The size of the image has been enhanced greatly so as to show a few details. Namely, the top left corner is marked in a red square. Also the marker is highlighted with a green line all round and the ID is written in blue. We can also see that there is a white area surrounding the markers that we may need to account for.\n",
    "\n",
    "Now that we have the corner points, we can establish our ROI which will be the corner of every marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0bdc1-4e03-413c-8eba-313d2a65ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ids = np.squeeze(ids)\n",
    "\n",
    "ids_corners = list(zip(new_ids, corners))\n",
    "ids_corners.sort(key = lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4964988-7b11-4e11-8115-a3575a1769d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_dst = []\n",
    "for i, elem in enumerate(ids_corners):\n",
    "    pts_dst.append(np.squeeze(elem[1])[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd48c806-d99b-490c-8937-55afcbc9d8dc",
   "metadata": {},
   "source": [
    "Now would be a good time to scale the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c5911-7825-4d46-9373-c89dad982e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_num = 4\n",
    "scale_array = np.array([[-scale_num, -scale_num], [scale_num, -scale_num], [scale_num, scale_num], [-scale_num, scale_num]])\n",
    "\n",
    "pts_dst_m = np.array([np.float32(m+n) for m,n in zip(pts_dst, scale_array)])\n",
    "pts_dst_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a05c85d-1f0a-4a5b-8a26-5d1990c84595",
   "metadata": {},
   "source": [
    "### Define Source Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408769fd-04bd-4ed2-9d12-6d8e4fe6cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load source image\n",
    "source = cv2.imread('images/Apollo-8-Launch.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.figure(figsize=[8, 8])\n",
    "plt.imshow(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b165c-b757-4a98-85d6-2a86d58fa664",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = source.shape\n",
    "src_pts = np.float32([[0, 0], [w-1, 0], [w-1, h-1], [0, h-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96186648-065c-4452-844b-e60dc9eeb0ea",
   "metadata": {},
   "source": [
    "### Homography, Masking and Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2708c-7346-45cc-a068-544f9f71ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = cv2.getPerspectiveTransform(src_pts, pts_dst_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55a282f-ec77-469b-b7cc-27dd93d51a2f",
   "metadata": {},
   "source": [
    "Now that we have the homography relating the two points, we need to warp the source image into the destination image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a4938-5935-4d58-882a-829b6d99faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find size of output image, using marker distance\n",
    "size_width = int(np.linalg.norm(pts_dst_m[0] - pts_dst_m[1]))\n",
    "size_height = int(np.linalg.norm(pts_dst_m[0] - pts_dst_m[3]))\n",
    "\n",
    "dst_apollo = cv2.warpPerspective(source, H, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "plt.imshow(dst_apollo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ba1c36-f278-4c51-9c04-5ac5d8a3d582",
   "metadata": {},
   "source": [
    "### Adding the two images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca9d228-fdbf-462b-8036-9275168df970",
   "metadata": {},
   "source": [
    "The next step is adding the two images. We do this by masking out the portion in the destination image that the source image is to be added into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19abdb4d-5557-4787-be42-196dced63166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the transformation of the points\n",
    "#src_pts_m = src_pts.reshape((-1, 1, 2))\n",
    "#corner_pts = cv2.perspectiveTransform(src_pts_m, H)\n",
    "frame_dst_final = cv2.fillPoly(frame, [np.int32(pts_dst_m)], (0, 0, 0))\n",
    "plt.imshow(frame_dst_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dde26b-3f16-403e-93bb-60e1513671c9",
   "metadata": {},
   "source": [
    "We now add the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b4bd8-eac1-45ff-8c40-e4c3b4269ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_apollo_col = cv2.merge([dst_apollo, dst_apollo, dst_apollo])\n",
    "\n",
    "final_img = cv2.add(frame_dst_final, dst_apollo_col)\n",
    "plt.figure(figsize=[20, 20])\n",
    "plt.imshow(final_img); plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-env",
   "language": "python",
   "name": "opencv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
