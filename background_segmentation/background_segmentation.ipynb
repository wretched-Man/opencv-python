{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c605554c-8fa6-49df-a90b-9f2db97b6569",
   "metadata": {},
   "source": [
    "# Using background segmentation for motion detection in videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404ee37-93aa-4174-9101-70b09cbc2d9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "We are going to be using OpenCV to perform motion detection in a video. For this, we are going to use a technique called background subtraction. This is a technique in which we will compute a background for a video from a series of frames and then using that background, we will subtract changes in subsequent frames and make a mask from changes in subsequent frames. The non-zero pixels in the resultant mask identify the places where there is motion. We will then draw a bounding rectangle on the image to show these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee37020b-f356-4562-b94a-0a237e59ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be082a0-7eb0-4f45-a223-59e362cb8fdc",
   "metadata": {},
   "source": [
    "We will first create the video capture and video writer objects. Then, we will create the foreground masking object. The output video will contain the mask and the frame at that point. Let us first preview our video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eebc2b-d619-4d9f-a559-17932e4a7e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video = 'media/motion_test.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec77d27d-f385-446d-b664-c5e46ce45200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Load the video for playback. \n",
    "#clip = VideoFileClip(input_video)\n",
    "#clip.ipython_display(width = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c218569-5722-4732-b33d-4d4caf4c4ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating video capture objects\n",
    "video_cap = cv2.VideoCapture(input_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91834c64-24d8-450f-9dc4-cb57cdc217ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get total frames\n",
    "framecount = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#We create the framesize\n",
    "#Since our video will be two frames combined, it will\n",
    "#have a width of 2X the original\n",
    "frameheight = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "framewidth = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH) * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ae122-1cf1-4221-8463-6384414f8879",
   "metadata": {},
   "source": [
    "## Without erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc186ed6-7305-484d-a6f8-e896224bb4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a video writer\n",
    "video_writer = cv2.VideoWriter('motion_test_no_erode.mp4',\\\n",
    "                               int(video_cap.get(cv2.CAP_PROP_FOURCC)),\\\n",
    "                               video_cap.get(cv2.CAP_PROP_FPS),\\\n",
    "                              (framewidth, frameheight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f479906-9d85-419a-af83-395aa0a121c4",
   "metadata": {},
   "source": [
    "We will also create a helper function to annotate every frame of the output file with the frame number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64700aa8-eb41-44cd-9238-a7e53798ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper annotate function\n",
    "#It will take a frame and text and write it onto a file\n",
    "def markFrame(frame, text):\n",
    "    cv2.putText(frame, text, (0, 15), 2, 0.6, (0, 255, 0), 1)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ae1a58-3979-4f44-87f7-26c175c35922",
   "metadata": {},
   "source": [
    "Now to create the foreground mask object. OpenCv provides multiple algorithms for this whichcan be found [here](https://docs.opencv.org/4.x/d8/d38/tutorial_bgsegm_bg_subtraction.html). We will be using `BackgroundSubtractorMOG2` to create the foreground mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451bdaa-2cce-4570-91cc-0234d4807002",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgobj = cv2.createBackgroundSubtractorMOG2(history=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e9ce3a-61da-4108-a76c-72b058820771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now iterate through every frame to create a mask\n",
    "count = 0 #count no of frames\n",
    "while True:\n",
    "    ret, frame = video_cap.read()\n",
    "\n",
    "    #Nothing to read\n",
    "    if frame is None:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "    #Create a mask\n",
    "    fgmask = bgobj.apply(frame)\n",
    "\n",
    "    #We want to create a bounding rectangle on the moving\n",
    "    #portions of the image\n",
    "    #We find the coordinates of all non-zero pixels ...\n",
    "    #these represent where the images have changed\n",
    "    nonzero = cv2.findNonZero(fgmask)\n",
    "\n",
    "    #We will then create a rectangle that bounds all the\n",
    "    #points. We will use these points to draw our bounding\n",
    "    #rectangle\n",
    "    x1, y1, x2, y2 = cv2.boundingRect(nonzero)\n",
    "    \n",
    "    #We will concantenate the mask and frame to\n",
    "    #We mark both frames\n",
    "    #the original frame\n",
    "    origmarked = markFrame(frame, 'Frame: ' + str(count)\\\n",
    "                             + '/' + str(framecount))\n",
    "    \n",
    "    #for the mask, we make it 3 channel so as to mark it\n",
    "    color_mask = cv2.cvtColor(fgmask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    #marking the mask\n",
    "    fg_marked = markFrame(color_mask, 'Frame: ' +\\\n",
    "                    str(count) + '/' + str(framecount))\n",
    "\n",
    "    #We will now draw a bounding rectangle over the color image\n",
    "    cv2.rectangle(origmarked, (x1, y1), (x2, y2),\\\n",
    "                  (0, 255, 255), 4)\n",
    "    #We now concantenate the images horizontally\n",
    "    finalframe = np.hstack([fg_marked, origmarked])\n",
    "\n",
    "    #We will draw a dividing line between the two frames\n",
    "    cv2.line(finalframe, (int(framewidth/2), 0),\\\n",
    "                (int(framewidth/2), frameheight),\\\n",
    "                 (255, 255, 0), 5)\n",
    "\n",
    "    video_writer.write(finalframe)\n",
    "\n",
    "video_writer.release()\n",
    "video_cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ef129-249f-4e6b-937a-dd5768dd64a5",
   "metadata": {},
   "source": [
    "We are now going to open our file and see the final output video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c6befd-e939-4d33-9f32-2b712c8c2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video for playback. \n",
    "#clip_2 = VideoFileClip('motion_test_no_erode.mp4')\n",
    "#clip_2.ipython_display(width = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a691fd-22ed-4a92-912d-84a4c97b9d66",
   "metadata": {},
   "source": [
    "As we have seen in the video, there are bounding boxes in every frame (the bounding box is shown in yellow) even when there is no motion. We can solve this by using erosion in the image. Let us try again this time using erosion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31823269-f81b-445a-91d7-a9555dd74837",
   "metadata": {},
   "source": [
    "## Using erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756bcea2-b41a-43bf-bff0-56b59fa48de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_writer_erode = cv2.VideoWriter('motion_test_erode.mp4',\\\n",
    "                               int(video_cap.get(cv2.CAP_PROP_FOURCC)),\\\n",
    "                               video_cap.get(cv2.CAP_PROP_FPS),\\\n",
    "                              (framewidth, frameheight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b0a24-759a-4612-b550-1874de85cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now iterate through every frame to create a mask\n",
    "count = 0 #count no of frames\n",
    "while True:\n",
    "    ret, frame = video_cap.read()\n",
    "\n",
    "    #Nothing to read\n",
    "    if frame is None:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "    #Create a mask\n",
    "    fgmask = bgobj.apply(frame)\n",
    "\n",
    "    #We want to create a bounding rectangle on the moving\n",
    "    #portions of the image\n",
    "    #We find the coordinates of all non-zero pixels ...\n",
    "    #these represent where the images have changed\n",
    "\n",
    "    #we now erode, the only change we make\n",
    "    #create a kernel\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    fgmask_erode = cv2.erode(fgmask, kernel)\n",
    "    nonzero = cv2.findNonZero(fgmask_erode)\n",
    "\n",
    "    #We will then create a rectangle that bounds all the\n",
    "    #points. We will use these points to draw our bounding\n",
    "    #rectangle\n",
    "    x1, y1, x2, y2 = cv2.boundingRect(nonzero)\n",
    "    \n",
    "    #We will concantenate the mask and frame to\n",
    "    #We mark both frames\n",
    "    #the original frame\n",
    "    origmarked = markFrame(frame, 'Frame: ' + str(count)\\\n",
    "                             + '/' + str(framecount))\n",
    "    \n",
    "    #for the mask, we make it 3 channel so as to mark it\n",
    "    color_mask = cv2.cvtColor(fgmask_erode, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    #marking the mask\n",
    "    fg_marked = markFrame(color_mask, 'Frame: ' +\\\n",
    "                    str(count) + '/' + str(framecount))\n",
    "\n",
    "    #We will now draw a bounding rectangle over the color image\n",
    "    if nonzero is not None:\n",
    "        cv2.rectangle(origmarked, (x1, y1), (x2, y2),\\\n",
    "                      (0, 255, 255), 4)\n",
    "    #We now concantenate the images horizontally\n",
    "    finalframe = np.hstack([fg_marked, origmarked])\n",
    "\n",
    "    #We will draw a dividing line between the two frames\n",
    "    cv2.line(finalframe, (int(framewidth/2), 0),\\\n",
    "                (int(framewidth/2), frameheight),\\\n",
    "                 (255, 255, 0), 5)\n",
    "\n",
    "    video_writer_erode.write(finalframe)\n",
    "\n",
    "video_writer_erode.release()\n",
    "video_cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eb0755-1c2d-46b8-8f09-41c917d9ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video for playback. \n",
    "#clip_2 = VideoFileClip('motion_test_erode.mp4')\n",
    "#clip_2.ipython_display(width = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ad6b4-7c32-4fd1-9671-342c8fd5c5bd",
   "metadata": {},
   "source": [
    "In this second try, we see that the number of false positives has reduced. This is because we have applied erosion to the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc73845d-4c67-4c96-b8fc-acdcd909e88c",
   "metadata": {},
   "source": [
    "We have now seen how to do motion detection in OpenCV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-env",
   "language": "python",
   "name": "opencv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
