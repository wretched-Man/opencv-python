{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7be89e-2fc1-4a49-b067-e309655ae001",
   "metadata": {},
   "source": [
    "# Homography and perspective transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a0a3284-b635-42e7-8394-24ad5dea4013",
   "metadata": {},
   "source": [
    "We have already looked at affine transformations and we have seen the properties and the limitations that they have. Just to recap:\n",
    "\n",
    "An affine transform is any transform of the form\n",
    "$$\\begin{bmatrix}A_{00} & A_{01} & b_0\\\\A_{10} & A_{11} & b_1\\\\ 0 & 0 & 1\\end{bmatrix}$$\n",
    "\n",
    "but since the last row remains constant we can also write it like:\n",
    "$$\\begin{bmatrix}A_{00} & A_{01} & b_0\\\\A_{10} & A_{11} & b_1\\end{bmatrix}$$\n",
    "\n",
    "which is also the output of OpenCV's `getAffineTransform` as we saw earlier.\n",
    "\n",
    "We know that an affine transform gives us 6-degrees of freedom and that to get an affine transform of a 2D shape, we need three points from the source and 3 from the resultant shape. We also know that for affine transforms, parallel lines remain parallel and the ratios are preserved and that this limits us in what we can do.\n",
    "\n",
    "There is another type of matrix that allows us to do more than an affine transform would. This matrix is known as a homography matrix written as:\n",
    "\n",
    "$$\\begin{bmatrix}H_{11} & H_{12} & H_{13}\\\\H_{21} & H_{22} & H_{23}\\\\ H_{31} & H_{32} & 1\\end{bmatrix}$$\n",
    "\n",
    "It turns out that by not restricting ourselves to a 2x3 matrix, we can do much more. But before we look at what we can do with homography, let us look at how we get there in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88789e9-e3a0-43b1-bd97-a6375c319f8f",
   "metadata": {},
   "source": [
    "# Linear camera model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01411878-42e3-4b5f-9d3d-3a401d839a2e",
   "metadata": {},
   "source": [
    "Let's take a simple tour to see how we got to this homography matrix. In order to take an image, a camera needs to take the 3D world coordinates, convert them to 3D camera coordinates then convert them to 2D coordinates. The linear camera model, which enables us to do this can be written as:\n",
    "\n",
    "$$\\begin{bmatrix}\\tilde{u} \\\\ \\tilde{v} \\\\ \\tilde{w}\\end{bmatrix} = \\begin{bmatrix}C_{11} & C_{12} & C_{13} & C_{14}\\\\ C_{21} & C_{22} & C_{23} & C_{24}\\\\ C_{31} & C_{32} & C_{33} & 1\\end{bmatrix}\\begin{bmatrix}X \\\\ Y \\\\ Z \\\\ 1\\end{bmatrix}$$\n",
    "\n",
    "This 3x4 matrix that does this is known as a **projection matrix**. It maps the 3D world coordinates $[X, Y, Z]$ to pixel coordinates $[u, v]$. Let us focus in on it:\n",
    "$$\\begin{bmatrix}C_{11} & C_{12} & C_{13} & C_{14}\\\\ C_{21} & C_{22} & C_{23} & C_{24}\\\\ C_{31} & C_{32} & C_{33} & C_{34}\\end{bmatrix}$$\n",
    "\n",
    "This projection matrix can be decomposed into *extrinsic* and *intrinsic* camera parameters. Extrinsic parameters are those that are external to the camera and are concerned with transforming 3D world coordinates to 3D camera coordinates. Intrinsic parameters are concerned with the camera and transformation from 3D camera coordinates to 2D pixel coordinates. The extrinsic parameter equation is:\n",
    "\n",
    "$$\\begin{bmatrix}x_c \\\\ y_c \\\\ z_c \\\\ 1\\end{bmatrix} = \\begin{bmatrix}r_{11} & r_{12} & r_{13} & t_{14}\\\\ r_{21} & r_{22} & r_{23} & t_{24}\\\\ r_{31} & r_{32} & r_{33} & t_{34} \\\\ 0 & 0 & 0 & 1\\end{bmatrix} \\begin{bmatrix}X \\\\ Y \\\\ Z \\\\ 1\\end{bmatrix}$$\n",
    "\n",
    "The matrix doing this transformation contains a 3x3 rotation matrix and a 3x1 translation matrix. It can also be written as $\\begin{bmatrix}R & t \\\\ 0_{1x3} & 1 \\end{bmatrix}$.\n",
    "\n",
    "The intrinsic matrix equation can be written as:\n",
    "$$\\begin{bmatrix}\\tilde{u} \\\\ \\tilde{v} \\\\ \\tilde{w}\\end{bmatrix} = \\begin{bmatrix}f_x & 0 & o_x & 0\\\\ 0 & f_y & o_y & 0\\\\ 0 & 0 & 1 & 0\\end{bmatrix} \\begin{bmatrix}x_c \\\\ y_c \\\\ z_c \\\\ 1\\end{bmatrix}$$\n",
    "\n",
    "We note that the intrinsic matrix $M_{int}$ is a a familiar 3x3 matrix, an affine transform with $f_x, f_y$ as scale (scaling the object from world dimensions to camera sensor dimensions) and $o_x, o_y$ a translation (signifying displacement from the optical centre), in the x, y directions.\n",
    "\n",
    "Hence, the projection matrix can also be written as:\n",
    "$$\n",
    "\\begin{bmatrix}u \\\\ v \\\\ 1\\end{bmatrix} \\equiv\n",
    "\\begin{bmatrix}\\tilde{u} \\\\ \\tilde{v} \\\\ \\tilde{w}\\end{bmatrix} = \\begin{bmatrix}f_x & 0 & o_x & 0\\\\ 0 & f_y & o_y & 0\\\\ 0 & 0 & 1 & 0\\end{bmatrix} \\begin{bmatrix}r_{11} & r_{12} & r_{13} & t_{14}\\\\ r_{21} & r_{22} & r_{23} & t_{24}\\\\ r_{31} & r_{32} & r_{33} & t_{34} \\\\ 0 & 0 & 0 & 1\\end{bmatrix} \\begin{bmatrix}X \\\\ Y \\\\ Z \\\\ 1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In summary, from the furthest right, we have a 3D coordinate of a point in the world which we convert to a 3D coordinate in the camera using the extrinsic matrix. We then convert this 3D camera point to a 2D image point using the intrinsic matrix. We then convert this homogenous 2D coordinate to cartesian coordinates.\n",
    "\n",
    "This is the linear camera model and we will use it for camera callibration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed9ee1-86da-43f1-8173-3b1292363aaa",
   "metadata": {},
   "source": [
    "### Distortion Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513c307-4191-4926-901a-e4a92ccf2c74",
   "metadata": {},
   "source": [
    "It should be noted that a camera has distortion effects that have not been included in the linear camera matrix. Two major ones are *radial* and *tangential* distortion effects. Calculating these is necessary for proper camera callibration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1004d01-097c-4a68-8b82-27a1547b4828",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec39ce-c8d1-4a98-a649-007e4bdb6968",
   "metadata": {},
   "source": [
    "Camera calibration involves finding the projection matrix $P$ for a camera. Once these values are found, they can be used to undistort images. OpenCV provides us with a method for calibration `calibrateCamera` which returns the *camera intrinsics matrix*, the *distortion coefficients*, the *rotation matrix* $R$ and the *translation vector* $t$. We can then use these outputs to undistort images by this camera.\n",
    "\n",
    "We also have a method known as `solvePnP`, which we can use to get the location of the object being viewed. (Also, camera pose estimation problem) In this case we pass in the camera intrinsics and the distortion coefficients to get the external parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc11365-cdbe-4e9d-a65f-7e6f1e6e9925",
   "metadata": {},
   "source": [
    "## Planar Homography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1e426-31f6-4db6-9e17-1e8a9c9ef4c6",
   "metadata": {},
   "source": [
    "We have seen that the linear camera model allows us to represent a point at coordinates $(X, Y, Z)$ in the world as a pixel at coordinates $(u, v)$ in an image.\n",
    "\n",
    "Now let us imagine describing the position of not one point but all points in a fixed Z, i.e setting the origin on a plane with x, y within the plane and Z coming out of the plane (depth). Since these points are on a plane, we can rewrite our projective equation with z = 0:\n",
    "\n",
    "$$\\begin{bmatrix}\\tilde{u} \\\\ \\tilde{v} \\\\ \\tilde{w}\\end{bmatrix} = \\begin{bmatrix}C_{11} & C_{12} & C_{13} & C_{14}\\\\ C_{21} & C_{22} & C_{23} & C_{24}\\\\ C_{31} & C_{32} & C_{33} & 1\\end{bmatrix}    \\begin{bmatrix}X \\\\ Y \\\\ 0 \\\\ 1\\end{bmatrix}$$\n",
    "\n",
    "Consequently, the third column also goes, we are left with:\n",
    "\n",
    "$$\\begin{bmatrix}\\tilde{u} \\\\ \\tilde{v} \\\\ \\tilde{w}\\end{bmatrix} = \\begin{bmatrix}H_{11} & H_{12} & H_{13}\\\\H_{21} & H_{22} & H_{23}\\\\ H_{31} & H_{32} & 1\\end{bmatrix}\\begin{bmatrix}X \\\\ Y \\\\ 1\\end{bmatrix}$$\n",
    "\n",
    "We get the matrix we had earlier, a 3x3 matrix we call the **planar homography** which maps points in a plane to points in an image. At this point, there is no depth information like we start with in the linear camera model, we are only concerned with the $(X, Y)$ coordinates of a point in a plane.\n",
    "(The matrix is generally normalized with $h_{33} = 1$ or  $h_{11}^2 + h_{12}^2 + h_{13}^2 + h_{21}^2 + h_{22}^2 + h_{23}^2 + h_{31}^2 + h_{32}^2 + h_{33}^2 = 1$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c789bf-a9fb-4d9d-b732-38b3e18aed0d",
   "metadata": {},
   "source": [
    "## What can we do with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2123b071-92f0-4195-8bb9-5473f62ff0a5",
   "metadata": {},
   "source": [
    "Now that we know how we derive our 3x3 homography matrix, we ask: what can we do with this? Well, all we can really do is reshape one parallelogram into any other parallelogram of our choosing. In fact, this is what homography does, mapping one plane (a parallelogram) into another plane through a point. This means that we need at least 4 points from each plane to estimate a homography that connects these two planes. However, we are not confined to use 4 points only, which allows for more accuracy.\n",
    "\n",
    "Practical applications of homographies include:\n",
    "* **perspective rectification** - if we have an image in the wrong perspective, and we happen to know at least four points in the image that lie on the same plane, we can rectify the perspective of the image. For such an application, we only require 4 points from each plane.\n",
    "* **image alignment** - A photo of a filled form may not be in the proper perspective. We can align the form if we have a template of how it should look like. In this application, we would fare better if we can find as many similar points in each plane as possible to compute homographies.\n",
    "* **image stitching** - we can stitch multiple images together to create panoramas. Just like image alignment, we will fare much better with more than the required minimum of 4.\n",
    "\n",
    "We will next see these applications in action."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-env",
   "language": "python",
   "name": "opencv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
